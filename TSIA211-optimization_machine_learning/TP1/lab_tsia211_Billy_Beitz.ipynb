{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SD TSIA 211 TP1\n",
    "\n",
    "Billy Nicolas\n",
    "Beitz Enguerrand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Loading data\n",
    "\n",
    "data_matrix_train, COP_train, data_matrix_test, COP_test, names = np.load('data_center_data_matrix.npy', allow_pickle=True)\n",
    "\n",
    "# Constructing matrices for min_w ||A w - b||_2**2\n",
    "\n",
    "matrix_mean = np.mean(data_matrix_train, axis=0)\n",
    "M = data_matrix_train - matrix_mean\n",
    "matrix_std = np.std(M, axis=0)\n",
    "M = M / matrix_std\n",
    "\n",
    "A = np.hstack([M, np.ones((M.shape[0],1)), -(M.T * COP_train[:,3]).T])\n",
    "b = COP_train[:,3]\n",
    "\n",
    "# Constructing matrices for the test set\n",
    "\n",
    "M_test = (data_matrix_test - matrix_mean) / matrix_std\n",
    "A_test = np.hstack([M_test, np.ones((M_test.shape[0],1)), -(M_test.T * COP_test[:,3]).T])\n",
    "b_test = COP_test[:,3]\n",
    "\n",
    "# Loading raw data\n",
    "import pandas as pd\n",
    "data = pd.read_csv('Raw_Dataset_May.csv')\n",
    "\n",
    "def name_to_subcategory_and_details(col_name):\n",
    "    if np.isreal(col_name):\n",
    "        col_name = names[col_name]\n",
    "    indices = np.nonzero((data['NAME'] == col_name).values)[0]\n",
    "    if len(indices) > 0:\n",
    "        subcategory = data['SUBCATEGORY'].iloc[[indices[0]]].values[0]\n",
    "        details = data['DETAILS'].iloc[[indices[0]]].values[0]\n",
    "        return subcategory, details\n",
    "    else:\n",
    "        print('unknown name')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Question 3.1 \n",
    "\n",
    "Assuming $ A \\omega = b $\n",
    "$ y(t)= b(t)=(A \\omega )_t = \\tilde{x} (t) ^T \\omega _{1}  + \\omega _{0} - y(t) \\tilde{x}^T (t) \\omega _2 $\n",
    "\n",
    "so \n",
    "\n",
    "$ (1+ \\tilde{x} (t) \\omega _2) y(t) =  \\tilde{x} (t) ^T \\omega _{1}  + \\omega _{0} $\n",
    "\n",
    "so\n",
    "\n",
    "$ y(t)= \\frac{  \\tilde{x} (t) ^T \\omega _{1}  + \\omega _{0}}{1+ \\tilde{x} ^T (t) \\omega _2} $\n",
    "\n",
    "because $\\omega$  and $ x $ are vectore we can swap products:\n",
    "\n",
    "$ y(t)= \\frac{\\omega _{1} ^T \\tilde{x} (t)   + \\omega _{0}}{1+  \\omega _2  ^T \\tilde{x} (t)} $\n",
    "\n",
    "\n",
    "\n",
    "* Question 3.2 \n",
    "\n",
    "Solving with least squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "omega = np.linalg.lstsq(A, b, rcond = None)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Question 3.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "780.8984793523671\n"
     ]
    }
   ],
   "source": [
    "#evaluate solution on the test set\n",
    "y_pred = A_test @ omega\n",
    "\n",
    "mse_1 = np.sum((y_pred - b_test)**2)/len(b_test)\n",
    "\n",
    "print(mse_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Question 3.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Question 3.5\n",
    "\n",
    "La dérivée vaut: $ A^T(A \\omega -b) + \\lambda \\omega$\n",
    "\n",
    "La fonction étant convexe (forme quadratique), on aura bien la solution optimale."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Question 3.6  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nicolas\\AppData\\Local\\Temp\\ipykernel_20476\\4276898646.py:18: RuntimeWarning: invalid value encountered in matmul\n",
      "  L = np.linalg.norm(A.T @ A+ lbd*np.eye(len(A[0])))\n"
     ]
    }
   ],
   "source": [
    "lbd = 100\n",
    "\n",
    "def l2_regul(A,b,lbd,omega):\n",
    "    return 0.5*(np.linalg.norm(A @ omega - b)**2 +lbd*np.linalg.norm(omega)**2)\n",
    "\n",
    "def grad_l2_regul(A,b,lbd,omega):\n",
    "    return A.T @ (A @ omega - b) + lbd*omega\n",
    "\n",
    "def grad_descent(A,b,lbd,omega_init,tau,eps,max_iter):\n",
    "    omega = omega_init\n",
    "    for i in range(max_iter):\n",
    "        omega = omega - tau*grad_l2_regul(A,b,lbd,omega)\n",
    "        if np.linalg.norm(grad_l2_regul(A,b,lbd,omega)) < eps:\n",
    "            print('converged in', i, 'iterations')\n",
    "            break\n",
    "    return omega\n",
    "\n",
    "# On prend le pas donné par le coefficient de Lipschitz\n",
    "\n",
    "L = np.linalg.norm(A.T @ A+ lbd*np.eye(len(A[0])))\n",
    "omega_init = np.ones(len(A[0]))\n",
    "tau = 1/L\n",
    "eps = 1e-7\n",
    "max_iter = 10000\n",
    "\n",
    "omega_descent = grad_descent(A,b,lbd,omega_init,tau,eps,max_iter)\n",
    "\n",
    "y_pred_descent = A_test @ omega_descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.54428802  0.34637572 -0.0494747  ...  0.14722499  0.23911253\n",
      "  0.12784386]\n"
     ]
    }
   ],
   "source": [
    "print(omega_descent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1883546.7412086632\n"
     ]
    }
   ],
   "source": [
    "mse_2 = np.sum((y_pred_descent - b_test)**2) / len(b_test) \n",
    "print(mse_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Question 4.1\n",
    "\n",
    "$ f2 = \\frac{1}{2} || A \\omega - b || _2 ^2 $ \n",
    "\n",
    "$ g2 = \\lambda ||  \\omega || _1 $\n",
    "\n",
    "$ prox _{g 2} (x) = argmin _y ( g2(y) + 0.5 ||x-y|| )$\n",
    "\n",
    "$ grad f = A^T (A \\omega -b) $\n",
    "\n",
    "* Question 4.2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "def proximal_operator(x, g, tau):\n",
    "    objective = lambda y: g(y) + 1/(2*tau) * np.linalg.norm(y - x)**2\n",
    "    result = minimize(objective, x)\n",
    "    return result.x            \n",
    "\n",
    "def proximal_grad_descent(A,b,lbd,omega_init,g2,tau,eps,max_iter):\n",
    "    omega = omega_init\n",
    "    for i in range(max_iter):\n",
    "        omega = proximal_operator(omega-tau*grad_l2_regul(A,b,lbd,omega), g2, tau*lbd )\n",
    "        if np.linalg.norm(grad_l2_regul(A,b,lbd,omega)) < eps:\n",
    "            print('converged in', i, 'iterations')\n",
    "            break\n",
    "    return omega"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
